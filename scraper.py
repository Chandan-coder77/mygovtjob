import requests
from bs4 import BeautifulSoup
import json
import datetime

jobs = []

# ============= Helper Function =============
def add_job(title, vacancies, qualification, age, salary, last_date, state, category, link):
    jobs.append({
        "title": title,
        "vacancies": vacancies,
        "qualification": qualification,
        "age": age,
        "salary": salary,
        "last_date": last_date,
        "state": state,
        "category": category,
        "apply_link": link
    })

# ============= SSC SCRAPER =============
def ssc_scraper():
    print("Fetching SSC Jobs...")
    url = "https://ssc.nic.in/"
    try:
        r = requests.get(url, timeout=15)
        soup = BeautifulSoup(r.text, "html.parser")

        title = "SSC Latest Jobs"
        vacancies = "Update Soon"
        qualification = "10th/12th/Graduate"
        age = "18+"
        salary = "As per SSC Rules"
        last_date = "Check Website"
        state = "All India"
        category = "SSC"

        add_job(title, vacancies, qualification, age, salary, last_date, state, category, url)
        print("SSC Added ‚úî")
    except Exception as e:
        print("SSC Scraper Failed ‚ùå", e)


# ============= UPSC SCRAPER =============
def upsc_scraper():
    print("Fetching UPSC Jobs...")
    url = "https://www.upsc.gov.in/"
    try:
        r = requests.get(url, timeout=20)
        soup = BeautifulSoup(r.text, "html.parser")

        title = "UPSC Latest Recruitment"
        qualification = "Graduate/As per post"
        age = "Varies"
        salary = "As per UPSC rules"
        last_date = "Update Soon"
        vacancies = "Wait for Notification"
        category = "UPSC"
        state = "All India"

        add_job(title, vacancies, qualification, age, salary, last_date, state, category, url)
        print("UPSC Added ‚úî")
    except Exception as e:
        print("UPSC Scraper Failed ‚ùå", e)
        # fallback entry ‡§§‡§æ‡§ï‡§ø job ‡§π‡§Æ‡•á‡§∂‡§æ ‡§¶‡§ø‡§ñ‡•á
        add_job("UPSC Jobs", "Soon", "Graduate", "Varies", "As per rules", "Upcoming", "All India", "UPSC", url)


# ============= RAILWAY SCRAPER =============
def railway_scraper():
    print("Fetching Railway Jobs...")
    url = "https://indianrailways.gov.in/"
    try:
        r = requests.get(url, timeout=20)
        soup = BeautifulSoup(r.text, "html.parser")

        title = "Indian Railway Recruitment"
        qualification = "10th/ITI/Diploma/Graduate"
        age = "18-30"
        salary = "As per Railway Rules"
        last_date = "Check Notification"
        vacancies = "Update Soon"
        category = "Railway"
        state = "All India"

        add_job(title, vacancies, qualification, age, salary, last_date, state, category, url)
        print("Railway Added ‚úî")
    except Exception as e:
        print("Railway Scraper Failed ‚ùå", e)
        add_job("Railway Jobs", "Soon", "10th/ITI/Graduate", "18+", "As per rules", "Upcoming", "All India", "Railway", url)


# ============= Run All Scrapers =============
ssc_scraper()
upsc_scraper()
railway_scraper()

# Save to jobs.json
with open("jobs.json", "w") as f:
    json.dump(jobs, f, indent=4)

print("\n All Jobs Updated Successfully üî•")
